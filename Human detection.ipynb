{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-d57a50cfc3c0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-d57a50cfc3c0>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    python -m ipykernel install\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pip install ipykernel\n",
    "#python -m ipykernel install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOGCV = cv2.HOGDescriptor()\n",
    "HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
    "    \n",
    "    person = 1\n",
    "    for x,y,w,h in bounding_box_cordinates:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "    \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video from path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathVideo(path, writer):\n",
    "\n",
    "    video = cv2.VideoCapture(path)\n",
    "    check, frame = video.read()\n",
    "    if check == False:\n",
    "        print('Video Not Found. Please Enter a Valid Path (Full path of Video Should be Provided).')\n",
    "        return\n",
    "\n",
    "    print('Detecting people...')\n",
    "    while video.isOpened():\n",
    "        #check is True if reading was successful \n",
    "        check, frame =  video.read()\n",
    "\n",
    "        if check:\n",
    "            frame = imutils.resize(frame , width=min(800,frame.shape[1]))\n",
    "            frame = detect(frame)\n",
    "            \n",
    "            if writer is not None:\n",
    "                writer.write(frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key== ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "    result_image = detect(image)\n",
    "\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argsParser():\n",
    "    arg_parse = argparse.ArgumentParser()\n",
    "    arg_parse.add_argument(\"-v\", \"--video\", default=None, help=\"path to Video File \")\n",
    "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
    "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
    "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
    "    args = vars(arg_parse.parse_args())\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    HOGCV = cv2.HOGDescriptor()\n",
    "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py -i F:\\Computer Vision\\testimg.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py -c True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install opencv numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cv2.startWindowThread()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # reading the frame\n",
    "    ret, frame = cap.read()\n",
    "    # displaying the frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # breaking the loop if the user types q\n",
    "        # note that the video window must be highlighted!\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# the following is necessary on the mac,\n",
    "# maybe not on other platforms:\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to greyscale:\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    # apply threshold. all pixels with a level larger than 80 are shown in white. the others are shown in black:\n",
    "ret,frame = cv2.threshold(frame,80,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-i IMAGE] [-c CAMERA]\n",
      "                             [-o OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\bhavini jain\\AppData\\Roaming\\jupyter\\runtime\\kernel-cf76e9e7-8f8d-460e-b100-c481feb7730e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "def detect(frame):\n",
    "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
    "    \n",
    "    person = 1\n",
    "    for x,y,w,h in bounding_box_cordinates:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "        person += 1\n",
    "    \n",
    "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detectByPathVideo(path, writer):\n",
    "\n",
    "    video = cv2.VideoCapture(path)\n",
    "    check, frame = video.read()\n",
    "    if check == False:\n",
    "        print('Video Not Found. Please Enter a Valid Path (Full path of Video Should be Provided).')\n",
    "        return\n",
    "\n",
    "    print('Detecting people...')\n",
    "    while video.isOpened():\n",
    "        #check is True if reading was successful \n",
    "        check, frame =  video.read()\n",
    "\n",
    "        if check:\n",
    "            frame = imutils.resize(frame , width=min(800,frame.shape[1]))\n",
    "            frame = detect(frame)\n",
    "            \n",
    "            if writer is not None:\n",
    "                writer.write(frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key== ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectByCamera(writer):   \n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
    "\n",
    "    result_image = detect(image)\n",
    "\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true' : camera = True \n",
    "    else : camera = False\n",
    "\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
    "\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(ouput_path,writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video from path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])\n",
    "\n",
    "def argsParser():\n",
    "    arg_parse = argparse.ArgumentParser()\n",
    "    arg_parse.add_argument(\"-v\", \"--video\", default=None, help=\"path to Video File \")\n",
    "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
    "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
    "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
    "    args = vars(arg_parse.parse_args())\n",
    "\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    HOGCV = cv2.HOGDescriptor()\n",
    "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipykernel\n",
    "python -m ipykernel install\n",
    "\n",
    "conda install notebook ipykernel\n",
    "ipython kernelspec install-self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-i IMAGE] [-c CAMERA]\n",
      "                             [-o OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\bhavini jain\\AppData\\Roaming\\jupyter\\runtime\\kernel-3ba8a952-ca09-4539-abf1-87c971b01536.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "# import numpy as np\n",
    "import argparse\n",
    "\n",
    "\n",
    "def detect(frame):\n",
    "    bounding_box_cordinates, weights = HOGCV.detectMultiScale(frame, winStride=(4, 4), padding=(8, 8), scale=1.03)\n",
    "\n",
    "    person = 1\n",
    "    for x, y, w, h in bounding_box_cordinates:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Person {person}', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        person += 1\n",
    "\n",
    "    cv2.putText(frame, 'Status : Detecting ', (40, 40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.putText(frame, f'Total Persons : {person - 1}', (40, 70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.imshow('output', frame)\n",
    "    \n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detectByPathVideo(path, writer):\n",
    "    video = cv2.VideoCapture(path)\n",
    "    check, frame = video.read()\n",
    "    if not check:\n",
    "        print('Video Not Found. Please Enter a Valid Path (Full path of Video should be provided).')\n",
    "        return\n",
    "\n",
    "    print('Detecting people...')\n",
    "    while video.isOpened():\n",
    "        # check is True if reading was successful.\n",
    "        check, frame = video.read()\n",
    "\n",
    "        if check:\n",
    "            frame = imutils.resize(frame, width=min(800, frame.shape[1]))\n",
    "            frame = detect(frame)\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.write(frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def detectByCamera(writer):\n",
    "    video = cv2.VideoCapture(0)\n",
    "    print('Detecting people...')\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        frame = detect(frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def detectByPathImage(path, output_path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    image = imutils.resize(image, width=min(800, image.shape[1]))\n",
    "\n",
    "    result_image = detect(image)\n",
    "\n",
    "    if output_path is not None:\n",
    "        cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def humanDetector(args):\n",
    "    image_path = args[\"image\"]\n",
    "    video_path = args['video']\n",
    "    if str(args[\"camera\"]) == 'true':\n",
    "        camera = True\n",
    "    else:\n",
    "        camera = False\n",
    "\n",
    "    writer = None\n",
    "    if args['output'] is not None and image_path is None:\n",
    "        writer = cv2.VideoWriter(args['output'], cv2.VideoWriter_fourcc(*'JPG'), 10, (600, 600))\n",
    "\n",
    "    if camera:\n",
    "        print('[INFO] Opening Web Cam.')\n",
    "        detectByCamera(output_path, writer)\n",
    "    elif video_path is not None:\n",
    "        print('[INFO] Opening Video form path.')\n",
    "        detectByPathVideo(video_path, writer)\n",
    "    elif image_path is not None:\n",
    "        print('[INFO] Opening Image from path.')\n",
    "        detectByPathImage(image_path, args['output'])\n",
    "    sys.exit(0)    \n",
    "\n",
    "\n",
    "def argsParser():\n",
    "    arg_parse = argparse.ArgumentParser()\n",
    "    arg_parse.add_argument('-v', '--video', default=None, help='path to Video File')\n",
    "    arg_parse.add_argument('-i', '--image', default=None, help='path to Image File')\n",
    "    arg_parse.add_argument('-c', '--camera', default=False, help='set true if you want to use the camera.')\n",
    "    arg_parse.add_argument('-o', '--output', type=str, help='path to optional output video file.')\n",
    "    args = vars(arg_parse.parse_args())\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    HOGCV = cv2.HOGDescriptor()\n",
    "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    args = argsParser()\n",
    "    humanDetector(args=[])\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f88d3df1d4fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mHOGCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetSVMDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHOGDescriptor_getDefaultPeopleDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margsParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[0mhumanDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f88d3df1d4fa>\u001b[0m in \u001b[0;36margsParser\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0marg_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-c'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--camera'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'set true if you want to use the camera.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0marg_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'path to optional output video file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrecognized arguments: %s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2506\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2493\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2495\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2497\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting background model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5ab0c4525ed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeDelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "avg = None\n",
    "video = cv2.VideoCapture(\"pexels-zen-chung-5531141.mp4\")\n",
    "xvalues = list()\n",
    "motion = list()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "def find_majority(k):\n",
    "    myMap = {}\n",
    "    maximum = ( '', 0 ) #(occurring element, occurrences)\n",
    "    for n in k:\n",
    "        if n in myMap: myMap[n] += 1\n",
    "        else: myMap[n] = 1\n",
    "\n",
    "        #Keep track of maximum on the go\n",
    "        if myMap[n] > maximum[1]: maximum = (n,myMap[n])\n",
    "\n",
    "    return maximum\n",
    "\n",
    "while 1:\n",
    "    ret, frame = video.read()\n",
    "    flag = True\n",
    "    text=\"\"\n",
    "\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    if avg is None:\n",
    "        print (\"[INFO] starting background model...\")\n",
    "        avg = gray.copy().astype(\"float\")\n",
    "        continue\n",
    "\n",
    "    cv2.accumulateWeighted(gray, avg, 0.5)\n",
    "    frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg))\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    ret,cnts,hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 5000:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        xvalues.append(x)\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    flag = False\n",
    "    \n",
    "    no_x = len(xvalues)\n",
    "    \n",
    "    if (no_x > 2):\n",
    "        difference = xvalues[no_x - 1] - xvalues[no_x - 2]\n",
    "        if(difference > 0):\n",
    "            motion.append(1)\n",
    "        else:\n",
    "            motion.append(0)\n",
    "\n",
    "    if flag is True:\n",
    "        if (no_x > 5):\n",
    "            val, times = find_majority(motion)\n",
    "            if val == 1 and times >= 15:\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1\n",
    "                \n",
    "        xvalues = list()\n",
    "        motion = list()\n",
    "    \n",
    "    cv2.line(frame, (260, 0), (260,480), (0,255,0), 2)\n",
    "    cv2.line(frame, (420, 0), (420,480), (0,255,0), 2)\n",
    "    cv2.putText(frame, \"In: {}\".format(count1), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Out: {}\".format(count2), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Gray\",gray)\n",
    "    cv2.imshow(\"FrameDelta\",frameDelta)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
